<style>
.reveal h1, .reveal h2, .reveal h3 {
  word-wrap: normal;
  -moz-hyphens: none;
}

.small-code pre code {
  font-size: 15px;
}

.footer {
    color: black; background: #E8E8E8;
    position: fixed; top: 90%;
    text-align:center; width:100%;
}

.midcenter {
    position: fixed;
    top: 50%;
    left: 50%;
    width: 400px;
    height: 400px;
}

.footer {
    color: black; background: #E8E8E8;
    position: fixed; top: 50%;
    text-align:left; width:100%;
}
</style>

Predicting Closure of Businesses Based on Rating Behaviour
===
author: Jesus Ramos
date: `r format(Sys.Date(), format="%B %d %Y")`
transition: rotate
<div class="midcenter" style="background-color:transparent; border:0px; box-shadow:none; margin-left:-480px; margin-top:0px;">
<img src="http://vignette2.wikia.nocookie.net/fleck/images/c/c8/Yelp_Logo.png/revision/latest?cb=20110828035920"></img>
</div>

Motivation & Business Question
===
1. Knowing how your business is rated in Yelp as an aggregate is interesting, but unactionable.
2. Going deeper into how ratings and their stars behave through time can grant insights as to the moments when customer care and attention is more important.
3. Failing to preemptively pamper your customers at the right moment in time may create an effect that will ultimately reduce the profitability of the business.
4. Since 'service is discrete, but perception of service is continuous', bad service will have a lasting effect.
5. If accumulated, this effect will be enough to force the shutdown of the business.

## Question
> Can user ratings be used to predict business closure?

Methodology
===
1. Gather data .
2. Explore the relationship between critics' and users' ratings via a linear model.
3. Try to predict the rating from critics of a new game for a given platform given a user rating.

Linear Plot and Model
===
left: 60%
class: small-code
```{r, echo=F, fig.width=6, fig.height=5, fig.align='center'}
library(ggplot2)
library(dplyr)
# Data loading, cleaning and processing
ratingps4 <- read.csv('./metacriticdata-ps4.txt', header = F)
ratingps4 <- ratingps4 %>% mutate(Platform='PS4')

ratingsxbone <- read.csv('./metacriticdata-xbone.txt', header = F)
ratingsxbone <- ratingsxbone %>% mutate(Platform='XBoxOne')

ratingswiiu <- read.csv('./metacriticdata-wiiu.txt', header = F)
ratingswiiu <- ratingswiiu %>% mutate(Platform='WiiU')

ratingspc <- read.csv('./metacriticdata-pc.txt', header = F)
ratingspc <- ratingspc %>% mutate(Platform='PC')

ratings <- rbind(ratingps4,ratingsxbone,ratingswiiu,ratingspc)
names(ratings) <- c('CriticRating', 'GameName', 'UserRating', 'Platform')
ratings <- ratings %>% mutate(CriticRating=round(CriticRating/10,2))
ratings <- ratings %>% filter(UserRating!='tbd')
ratings <- ratings %>% mutate(CriticRating=as.numeric(CriticRating), UserRating=as.numeric(UserRating))
platforms <- c('All',unique(ratings$Platform))

# Linear models
lmRatingsByPlat <- lm(CriticRating ~ UserRating * Platform, ratings)
lmRatings <- lm(CriticRating ~ UserRating, ratings)

# Plot
qplot(x=UserRating, y=CriticRating, data=ratings, color=Platform, geom=c('point','smooth'), method='lm',xlab="Users' Rating", ylab="Critics' Rating") + geom_line(x=ratings$UserRating, y=lmRatings$fitted.values, color=I('black'))

round(summary(lmRatingsByPlat)$coef[,-3],2)
```
***
<font size="5">According to the figures, every 1-point increment in user ratings brings a *`r round(coef(lmRatings)[2],2)`* increase in critic ratings. Though this relationship is very significant at a p-value of *`r round(summary(lmRatings)$coeff[2,4],2)`*, it only explains *`r round(summary(lmRatings)$r.squared*100,2)`%* of the variance. However, if we control for platform we can account for *`r round(summary(lmRatingsByPlat)$r.squared*100,2)`%* of the variance, but then the only good predictor between ratings is for WiiU.</font>

Conclusion & Pitch
===
1. Even though the prediction for platforms other than WiiU may not be so reliable, it is nonetheless interesting to observe how for more 'hardcore' platforms users give a wider range of ratings than critics, while for more 'family-friendly' platforms users and critics are more consistent.
2. To explore this relationship, the difference in ratings for the titles, and to estimate a critic rating from a user rating (regardless of the confidence on the prediction) for a new game, we have developed a Shiny app.
3. The Shiny app can be found *[here](https://jsramos.shinyapps.io/dataproducts)*. We submit it for your consideration. Enjoy!